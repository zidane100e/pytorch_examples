{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader\n",
    "* reference : Natural language processing with PYTORCH\n",
    "1. load data file into a dataframe\n",
    "2. modify text with right form using tokenizer or corpus\n",
    "3. change modified text into vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, string\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.device_count()>1:\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "elif torch.cuda.device_count()>0:\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from torchtext import data as ttdata\n",
    "from torchtext.data import Dataset, Example, Field\n",
    "from torchtext.data import Iterator, BucketIterator\n",
    "\n",
    "class TextData():    \n",
    "    def __init__(self, df_train, df_test, df_valid=None):\n",
    "        self.df = {}\n",
    "        self.df['train'] = df_train\n",
    "        self.df['test'] = df_test\n",
    "        if df_valid is None:\n",
    "            self.df['valid'] = df_test\n",
    "        else:\n",
    "            self.df['valid'] = df_valid\n",
    "                    \n",
    "        self.init_field()\n",
    "        self.data_setting = 'train'\n",
    "        self.dataset = {}\n",
    "    \n",
    "    def set_data_setting(self, setting):\n",
    "        self.data_setting = setting\n",
    "        \n",
    "    def init_field(self):\n",
    "        self.field_x_name = 'data_x'\n",
    "        self.field_x = Field(sequential=True, use_vocab=True,\n",
    "                 tokenize='spacy', lower=True,\n",
    "                 batch_first=True, fix_length=100,\n",
    "                 init_token='<SOS>', eos_token='<EOS>'\n",
    "                 )\n",
    "        self.field_y_name = 'data_y'\n",
    "        self.field_y = Field(sequential=False, use_vocab=False,\n",
    "                  batch_first=False, is_target=True)\n",
    "        self.fields = ((self.field_x_name, self.field_x),\n",
    "                     (self.field_y_name, self.field_y))\n",
    "    \n",
    "    def _get_dataset(self, setting='train'):\n",
    "        self.data_setting = setting\n",
    "        train_data = []\n",
    "        for ii in range(len(self.df[setting])):\n",
    "            temp = Example.fromlist(\n",
    "                        self.df[setting].iloc[ii].values.tolist(),\n",
    "                              self.fields)\n",
    "            train_data.append(temp)\n",
    "        self.dataset[setting] = Dataset(train_data, fields=self.fields)\n",
    "        return self.dataset[setting]\n",
    "        \n",
    "    def _generate_vocab(self, min_freq=10, max_size=20000):\n",
    "        try:\n",
    "            self.dataset\n",
    "        except:\n",
    "            self._get_dataset('train')\n",
    "        self.field_x.build_vocab(self.dataset['train'], \n",
    "                                 min_freq=min_freq, \n",
    "                                 max_size=max_size)\n",
    "        self.vocab = self.field_x.vocab\n",
    "        self.n_vocab = len(self.vocab.itos)\n",
    "        return self.vocab\n",
    "    \n",
    "    def set_batch(self, batch_size, setting='train', \n",
    "                  min_freq=10, max_size=20000):\n",
    "        try: \n",
    "            self.dataset[setting]\n",
    "        except:\n",
    "            self._get_dataset(setting)\n",
    "            self._generate_vocab(min_freq, max_size)\n",
    "        try:\n",
    "            self.iter\n",
    "        except:\n",
    "            self.iter = Iterator(self.dataset[setting], \n",
    "                                 batch_size=batch_size)\n",
    "            \n",
    "    def get_batch(self):\n",
    "        for batch in iter(self.iter):\n",
    "            xs = getattr(batch, 'data_x')\n",
    "            ys = getattr(batch, 'data_y')\n",
    "            xs = xs.to(device)\n",
    "            ys = ys.to(device)\n",
    "            yield xs, ys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "data shape\n",
    "rating, review, split\n",
    "negative, \"sentence\", train\n",
    "positive, \"sentence\", train\n",
    "\"\"\"\n",
    "f1_s = \"/home/bwlee/data/yelp_review_polarity_csv/reviews_with_splits_full.csv\"\n",
    "\n",
    "#df = pd.read_csv(f1_s, header=0)\n",
    "#df = pd.read_csv(f1_s, header=0, nrows=100)\n",
    "df = pd.read_csv(f1_s, header=0, nrows = 100, \n",
    "                 skiprows=lambda x: x%7000>0)\n",
    "label0 = []\n",
    "for i in df.index: # change this for getting info based on previous day market move\n",
    "    if df['rating'].iloc[i] == 'positive':\n",
    "        label0.append(1)\n",
    "    else:\n",
    "        label0.append(0)\n",
    "df['rating'] = label0\n",
    "\n",
    "train_df = df[df['split']=='train'][['review','rating']] \n",
    "val_df = df[df['split']=='val'][['review','rating']]\n",
    "test_df = df[df['split']=='test'][['review','rating']]\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "val_df = val_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = TextData(train_df, test_df)\n",
    "data.set_batch(10)\n",
    "batches = data.get_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'took'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 0, 1, 1, 0, 1, 1, 0, 1], device='cuda:0')\n",
      "tensor([0, 1, 1, 0, 1, 1, 1, 0, 0, 0], device='cuda:0')\n",
      "tensor([1, 0, 1, 1, 0, 0, 1, 1, 0, 0], device='cuda:0')\n",
      "tensor([0, 0, 1, 0, 1, 1, 1, 0, 1, 1], device='cuda:0')\n",
      "tensor([1, 1, 0, 1, 0, 0, 0, 0, 1, 0], device='cuda:0')\n",
      "tensor([0, 0, 1, 1, 0, 0], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for x, y in batches:\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and DataLoader\n",
    "* Dataset gets data\n",
    "* map-style, iterable style\n",
    "    * map-style(Dataset) :  needs __getitem__(), __len__()\n",
    "    * iterable style(IterableDataset) : needs __iter__()\n",
    "* DataLoader transform Dataset into batch and tensors\n",
    "```python\n",
    "torch.utils.data.Dataset\n",
    "torch.utils.data.TensorDataset(*tensors)\n",
    "# *tensors (Tensor) â€“ tensors that have the same size of the first dimension.\n",
    "```\n",
    "* TensorDataset can be used for multiple data with a condition for dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader\n",
    "* if it None, batch is not applied\n",
    "* defau;t batch_size is 1\n",
    "* batch_sampler works for map-style datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torchtext : DataLoader, Iterator\n",
    "* There's another dataloader for text in torchtext\n",
    "* This has various open dataset\n",
    "* It is still cumbersome in reading from dataframe\n",
    "* In case, if you read directly from TSV, CSV, JSON, ...  \n",
    "You can use TabularDataset\n",
    "* torchtext.data.Dataset requires Example type of data\n",
    "    * You need to make Example for each data instance  \n",
    "      and give it as input    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can use several type of tokenizer.\n",
    "In here, we use spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If dataset is made, we can generate vocabulary.  \n",
    "If a vocabulary is established, dataloader vectorize  \n",
    "each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'great'"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.vocab.itos[58]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.vocab.stoi['i']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
